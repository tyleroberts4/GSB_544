{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    code-fold: true\n",
        "    embed-resources: true\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "IHauUF6Sr5nK"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import ggplot, aes, geom_point, labs, facet_wrap, geom_abline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.compose import make_column_selector, ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "An0sVYiwtYQO"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"Data/Hitters.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "yecEoTrRtl0V",
        "outputId": "1c7d479d-5001-4da9-b941-979dbd9b020e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AtBat</th>\n",
              "      <th>Hits</th>\n",
              "      <th>HmRun</th>\n",
              "      <th>Runs</th>\n",
              "      <th>RBI</th>\n",
              "      <th>Walks</th>\n",
              "      <th>Years</th>\n",
              "      <th>CAtBat</th>\n",
              "      <th>CHits</th>\n",
              "      <th>CHmRun</th>\n",
              "      <th>CRuns</th>\n",
              "      <th>CRBI</th>\n",
              "      <th>CWalks</th>\n",
              "      <th>League</th>\n",
              "      <th>Division</th>\n",
              "      <th>PutOuts</th>\n",
              "      <th>Assists</th>\n",
              "      <th>Errors</th>\n",
              "      <th>Salary</th>\n",
              "      <th>NewLeague</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>293</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>29</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>29</td>\n",
              "      <td>14</td>\n",
              "      <td>A</td>\n",
              "      <td>E</td>\n",
              "      <td>446</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>315</td>\n",
              "      <td>81</td>\n",
              "      <td>7</td>\n",
              "      <td>24</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>14</td>\n",
              "      <td>3449</td>\n",
              "      <td>835</td>\n",
              "      <td>69</td>\n",
              "      <td>321</td>\n",
              "      <td>414</td>\n",
              "      <td>375</td>\n",
              "      <td>N</td>\n",
              "      <td>W</td>\n",
              "      <td>632</td>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>475.0</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>479</td>\n",
              "      <td>130</td>\n",
              "      <td>18</td>\n",
              "      <td>66</td>\n",
              "      <td>72</td>\n",
              "      <td>76</td>\n",
              "      <td>3</td>\n",
              "      <td>1624</td>\n",
              "      <td>457</td>\n",
              "      <td>63</td>\n",
              "      <td>224</td>\n",
              "      <td>266</td>\n",
              "      <td>263</td>\n",
              "      <td>A</td>\n",
              "      <td>W</td>\n",
              "      <td>880</td>\n",
              "      <td>82</td>\n",
              "      <td>14</td>\n",
              "      <td>480.0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>496</td>\n",
              "      <td>141</td>\n",
              "      <td>20</td>\n",
              "      <td>65</td>\n",
              "      <td>78</td>\n",
              "      <td>37</td>\n",
              "      <td>11</td>\n",
              "      <td>5628</td>\n",
              "      <td>1575</td>\n",
              "      <td>225</td>\n",
              "      <td>828</td>\n",
              "      <td>838</td>\n",
              "      <td>354</td>\n",
              "      <td>N</td>\n",
              "      <td>E</td>\n",
              "      <td>200</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>500.0</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>321</td>\n",
              "      <td>87</td>\n",
              "      <td>10</td>\n",
              "      <td>39</td>\n",
              "      <td>42</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>396</td>\n",
              "      <td>101</td>\n",
              "      <td>12</td>\n",
              "      <td>48</td>\n",
              "      <td>46</td>\n",
              "      <td>33</td>\n",
              "      <td>N</td>\n",
              "      <td>E</td>\n",
              "      <td>805</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>91.5</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   AtBat  Hits  HmRun  Runs  RBI  ...  PutOuts  Assists  Errors  Salary  NewLeague\n",
              "0    293    66      1    30   29  ...      446       33      20     NaN          A\n",
              "1    315    81      7    24   38  ...      632       43      10   475.0          N\n",
              "2    479   130     18    66   72  ...      880       82      14   480.0          A\n",
              "3    496   141     20    65   78  ...      200       11       3   500.0          N\n",
              "4    321    87     10    39   42  ...      805       40       4    91.5          N\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years', 'CAtBat',\n",
              "       'CHits', 'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'League', 'Division',\n",
              "       'PutOuts', 'Assists', 'Errors', 'Salary', 'NewLeague'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data.drop(columns=[\"Salary\"])\n",
        "y = data[\"Salary\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "ct = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"select\", StandardScaler(), ['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years', 'CAtBat', 'CHits',\n",
        "       'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'PutOuts',\n",
        "       'Assists', 'Errors']),\n",
        "        (\"dummify\", OneHotEncoder(sparse_output = False, handle_unknown=\"ignore\"), [\"League\",'Division','NewLeague'])\n",
        "\n",
        "    ],\n",
        "    remainder = \"passthrough\"\n",
        ").set_output(transform = \"pandas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A. Regression without regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>select__CRuns</td>\n",
              "      <td>480.747135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>select__Hits</td>\n",
              "      <td>337.830479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>select__CRBI</td>\n",
              "      <td>260.689886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>select__Walks</td>\n",
              "      <td>135.073897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>select__CHits</td>\n",
              "      <td>86.687617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>select__PutOuts</td>\n",
              "      <td>78.761296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>dummify__Division_E</td>\n",
              "      <td>58.424623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>select__Assists</td>\n",
              "      <td>53.732490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>select__HmRun</td>\n",
              "      <td>37.853837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>dummify__League_N</td>\n",
              "      <td>31.299712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>dummify__NewLeague_A</td>\n",
              "      <td>12.381163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>dummify__NewLeague_N</td>\n",
              "      <td>-12.381163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>select__CHmRun</td>\n",
              "      <td>-14.181723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>select__Years</td>\n",
              "      <td>-16.693359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>select__Errors</td>\n",
              "      <td>-22.160862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>select__RBI</td>\n",
              "      <td>-26.994984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>dummify__League_A</td>\n",
              "      <td>-31.299712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>dummify__Division_W</td>\n",
              "      <td>-58.424623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>select__Runs</td>\n",
              "      <td>-60.572479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>select__CWalks</td>\n",
              "      <td>-213.892259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>select__AtBat</td>\n",
              "      <td>-291.094556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>select__CAtBat</td>\n",
              "      <td>-391.038655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Feature        Coef\n",
              "10         select__CRuns  480.747135\n",
              "1           select__Hits  337.830479\n",
              "11          select__CRBI  260.689886\n",
              "5          select__Walks  135.073897\n",
              "8          select__CHits   86.687617\n",
              "13       select__PutOuts   78.761296\n",
              "18   dummify__Division_E   58.424623\n",
              "14       select__Assists   53.732490\n",
              "2          select__HmRun   37.853837\n",
              "17     dummify__League_N   31.299712\n",
              "20  dummify__NewLeague_A   12.381163\n",
              "21  dummify__NewLeague_N  -12.381163\n",
              "9         select__CHmRun  -14.181723\n",
              "6          select__Years  -16.693359\n",
              "15        select__Errors  -22.160862\n",
              "4            select__RBI  -26.994984\n",
              "16     dummify__League_A  -31.299712\n",
              "19   dummify__Division_W  -58.424623\n",
              "3           select__Runs  -60.572479\n",
              "12        select__CWalks -213.892259\n",
              "0          select__AtBat -291.094556\n",
              "7         select__CAtBat -391.038655"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_1 = Pipeline([\n",
        "    (\"prepocessing\", ct),\n",
        "    (\"linereg\", LinearRegression())\n",
        "])\n",
        "\n",
        "pipe_1_fitted = pipe_1.fit(X,y)\n",
        "\n",
        "\n",
        "feature_names = pipe_1_fitted.named_steps['prepocessing'].get_feature_names_out()\n",
        "pipe_1_fitted_coefs = pipe_1_fitted.named_steps['linereg'].coef_\n",
        "coef_df_pipe_1 = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Coef\":pipe_1_fitted_coefs })\n",
        "\n",
        "coef_df_pipe_1.sort_values(by='Coef', ascending=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. interpret a few of the most important coefficients:\n",
        "In the model Career Runs has the most impact on salary, for every 1 run increase in a players career their salary increases by 480 thousand dollars. This makes as players who have played more likely have bigger contracts and have scored more runs. Also the highest paid guys likely score a lot. Hit and RBIs also increase salary by a lot in this model which shows success at the plate leads to higher salaries. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(121136.31031816891)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_1_MSE = cross_val_score(pipe_1, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "pipe_1_mse_scores = -pipe_1_MSE\n",
        "pipe_1_mse_scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. MSE = 121136.31031816891"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "B. Ridge regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_ridgereg__alpha</th>\n",
              "      <th>mean_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000</td>\n",
              "      <td>-119144.432677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.000</td>\n",
              "      <td>-119348.984776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.100</td>\n",
              "      <td>-120343.621067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.010</td>\n",
              "      <td>-121022.903286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001</td>\n",
              "      <td>-121124.458592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   param_ridgereg__alpha  mean_test_score\n",
              "3                  1.000   -119144.432677\n",
              "4                 10.000   -119348.984776\n",
              "2                  0.100   -120343.621067\n",
              "1                  0.010   -121022.903286\n",
              "0                  0.001   -121124.458592"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_2 = Pipeline([\n",
        "    (\"prepocessing\", ct),\n",
        "    (\"ridgereg\", Ridge())\n",
        "]).set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'ridgereg__alpha': [0.001,0.01,0.1,1,10]}\n",
        "\n",
        "gscv_ridge = GridSearchCV(pipe_2, alphas, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_ridge = gscv_ridge.fit(X, y)\n",
        "\n",
        "gscv_fitted_ridge.cv_results_['mean_test_score']\n",
        "df_ridge= pd.DataFrame(gscv_fitted_ridge.cv_results_)\n",
        "\n",
        "ridge_results = df_ridge[['param_ridgereg__alpha', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False)\n",
        "ridge_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>select__CRuns</td>\n",
              "      <td>320.412169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>select__Hits</td>\n",
              "      <td>296.645050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>select__CRBI</td>\n",
              "      <td>160.386784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>select__CHits</td>\n",
              "      <td>126.659607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>select__Walks</td>\n",
              "      <td>124.407173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>select__PutOuts</td>\n",
              "      <td>78.623656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>dummify__Division_E</td>\n",
              "      <td>60.015595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>select__Assists</td>\n",
              "      <td>47.462597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>select__CHmRun</td>\n",
              "      <td>39.070924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>dummify__League_N</td>\n",
              "      <td>30.438855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>select__HmRun</td>\n",
              "      <td>18.100592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>dummify__NewLeague_A</td>\n",
              "      <td>13.111282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>select__RBI</td>\n",
              "      <td>-9.113295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>dummify__NewLeague_N</td>\n",
              "      <td>-13.111282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>select__Errors</td>\n",
              "      <td>-23.724190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>select__Runs</td>\n",
              "      <td>-29.339406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>dummify__League_A</td>\n",
              "      <td>-30.438855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>select__Years</td>\n",
              "      <td>-38.667748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>dummify__Division_W</td>\n",
              "      <td>-60.015595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>select__CWalks</td>\n",
              "      <td>-184.423611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>select__CAtBat</td>\n",
              "      <td>-225.406548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>select__AtBat</td>\n",
              "      <td>-270.686441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Feature        Coef\n",
              "10         select__CRuns  320.412169\n",
              "1           select__Hits  296.645050\n",
              "11          select__CRBI  160.386784\n",
              "8          select__CHits  126.659607\n",
              "5          select__Walks  124.407173\n",
              "13       select__PutOuts   78.623656\n",
              "18   dummify__Division_E   60.015595\n",
              "14       select__Assists   47.462597\n",
              "9         select__CHmRun   39.070924\n",
              "17     dummify__League_N   30.438855\n",
              "2          select__HmRun   18.100592\n",
              "20  dummify__NewLeague_A   13.111282\n",
              "4            select__RBI   -9.113295\n",
              "21  dummify__NewLeague_N  -13.111282\n",
              "15        select__Errors  -23.724190\n",
              "3           select__Runs  -29.339406\n",
              "16     dummify__League_A  -30.438855\n",
              "6          select__Years  -38.667748\n",
              "19   dummify__Division_W  -60.015595\n",
              "12        select__CWalks -184.423611\n",
              "7         select__CAtBat -225.406548\n",
              "0          select__AtBat -270.686441"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_pipe_ridge = Pipeline([\n",
        "    (\"prepocessing\", ct),\n",
        "    (\"ridgereg\", Ridge(alpha=1))\n",
        "]).set_output(transform=\"pandas\")\n",
        "\n",
        "best_fitted_ridge = best_pipe_ridge.fit(X, y)\n",
        "\n",
        "feature_names = best_fitted_ridge.named_steps['prepocessing'].get_feature_names_out()\n",
        "ridge_fitted_coefs = best_fitted_ridge.named_steps['ridgereg'].coef_\n",
        "coef_df_ridge = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Coef\":ridge_fitted_coefs })\n",
        "\n",
        "coef_df_ridge.sort_values(by='Coef', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. The Ridge coefficients show that long-term offensive production (CRuns, Hits, CRBIs) is most strongly associated with salary. Because Ridge keeps correlated predictors in the model instead of dropping them, it spreads influence across this group but still highlights which variables matter most. 1 unit increase in CRuns increases salary by 320 thousand dollars and for hits 296 thousand dollars."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. MSE = 119144.432677"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C. Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.983e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.108e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.537e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.591e+06, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.056e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.589e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e+05, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.065e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.977e+04, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+05, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+05, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+04, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.296e+05, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.808e+03, tolerance: 4.281e+03\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_lasso_regression__alpha</th>\n",
              "      <th>mean_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000</td>\n",
              "      <td>-119761.628313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.100</td>\n",
              "      <td>-120682.219611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.010</td>\n",
              "      <td>-120964.767703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001</td>\n",
              "      <td>-120994.180175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.000</td>\n",
              "      <td>-121828.102220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   param_lasso_regression__alpha  mean_test_score\n",
              "3                          1.000   -119761.628313\n",
              "2                          0.100   -120682.219611\n",
              "1                          0.010   -120964.767703\n",
              "0                          0.001   -120994.180175\n",
              "4                         10.000   -121828.102220"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lasso_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"lasso_regression\", Lasso())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'lasso_regression__alpha': [0.001,0.01,0.1,1,10]}\n",
        "\n",
        "\n",
        "gscv_lasso = GridSearchCV(lasso_pipeline, alphas, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_lasso = gscv_lasso.fit(X, y)\n",
        "\n",
        "gscv_fitted_lasso.cv_results_['mean_test_score']\n",
        "df_lasso= pd.DataFrame(gscv_fitted_lasso.cv_results_)\n",
        "\n",
        "lasso_results = df_lasso[['param_lasso_regression__alpha', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False)\n",
        "lasso_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>select__CRuns</td>\n",
              "      <td>3.755650e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>select__Hits</td>\n",
              "      <td>3.043583e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>select__CRBI</td>\n",
              "      <td>1.926164e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>select__Walks</td>\n",
              "      <td>1.206948e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>dummify__Division_E</td>\n",
              "      <td>1.144130e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>select__PutOuts</td>\n",
              "      <td>7.876026e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>select__Assists</td>\n",
              "      <td>4.199666e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>select__CHmRun</td>\n",
              "      <td>1.422286e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>select__HmRun</td>\n",
              "      <td>1.112715e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>dummify__League_N</td>\n",
              "      <td>1.908192e-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>dummify__NewLeague_N</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>dummify__NewLeague_A</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>select__RBI</td>\n",
              "      <td>-0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>select__CHits</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>dummify__Division_W</td>\n",
              "      <td>-2.162128e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>select__Errors</td>\n",
              "      <td>-1.847942e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>select__Runs</td>\n",
              "      <td>-2.496605e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>select__Years</td>\n",
              "      <td>-3.494751e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>dummify__League_A</td>\n",
              "      <td>-3.582608e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>select__CAtBat</td>\n",
              "      <td>-1.626441e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>select__CWalks</td>\n",
              "      <td>-1.896431e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>select__AtBat</td>\n",
              "      <td>-2.823696e+02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Feature          Coef\n",
              "10         select__CRuns  3.755650e+02\n",
              "1           select__Hits  3.043583e+02\n",
              "11          select__CRBI  1.926164e+02\n",
              "5          select__Walks  1.206948e+02\n",
              "18   dummify__Division_E  1.144130e+02\n",
              "13       select__PutOuts  7.876026e+01\n",
              "14       select__Assists  4.199666e+01\n",
              "9         select__CHmRun  1.422286e+01\n",
              "2          select__HmRun  1.112715e+01\n",
              "17     dummify__League_N  1.908192e-14\n",
              "21  dummify__NewLeague_N -0.000000e+00\n",
              "20  dummify__NewLeague_A  0.000000e+00\n",
              "4            select__RBI -0.000000e+00\n",
              "8          select__CHits  0.000000e+00\n",
              "19   dummify__Division_W -2.162128e-11\n",
              "15        select__Errors -1.847942e+01\n",
              "3           select__Runs -2.496605e+01\n",
              "6          select__Years -3.494751e+01\n",
              "16     dummify__League_A -3.582608e+01\n",
              "7         select__CAtBat -1.626441e+02\n",
              "12        select__CWalks -1.896431e+02\n",
              "0          select__AtBat -2.823696e+02"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_lasso_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"lasso_regression\", Lasso(alpha=1))]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "best_fitted_lasso = best_lasso_pipeline.fit(X, y)\n",
        "\n",
        "feature_names = best_fitted_lasso.named_steps['preprocessing'].get_feature_names_out()\n",
        "lasso_fitted_coefs = best_fitted_lasso.named_steps['lasso_regression'].coef_\n",
        "coef_df_lasso = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Coef\":lasso_fitted_coefs })\n",
        "\n",
        "coef_df_lasso.sort_values(by='Coef', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. CRuns still is the largest postive coefficient with one unit increase rsulting in salary increase of 3.755650e+02. RBI , CHit, and some league variables were set to 0. This is because LASSO makes many weaker or redundant predictors, such as categorical indicators or highly correlated batting stats, set to exactly zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. MSE = 119761.628313"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "D. Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.137e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.359e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.710e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.053e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.241e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.994e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.059e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.981e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.699e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.553e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.479e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.543e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+05, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.353e+04, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.114e+05, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+04, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.065e+04, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.639e+05, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.977e+05, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.665e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+05, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.744e+05, tolerance: 4.558e+03\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_elasticnet_regression__alpha</th>\n",
              "      <th>param_elasticnet_regression__l1_ratio</th>\n",
              "      <th>mean_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.90</td>\n",
              "      <td>-118969.491456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.010</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-118973.789406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.010</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-119009.799631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-119036.415623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-119123.789921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-119381.375758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.010</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-119404.656366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-119636.170153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-119745.310236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.90</td>\n",
              "      <td>-119856.902065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.010</td>\n",
              "      <td>0.90</td>\n",
              "      <td>-119896.666355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-119972.790018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-120077.757760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-120296.194969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-120356.605501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-120590.431840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-120775.681590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.90</td>\n",
              "      <td>-120817.247724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-121374.333354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-121760.921951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>10.000</td>\n",
              "      <td>0.90</td>\n",
              "      <td>-123257.386236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>10.000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-128407.506308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>10.000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-136766.429438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>10.000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-144021.731300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>10.000</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-147771.744726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    param_elasticnet_regression__alpha  ...  mean_test_score\n",
              "14                               0.100  ...   -118969.491456\n",
              "5                                0.010  ...   -118973.789406\n",
              "6                                0.010  ...   -119009.799631\n",
              "13                               0.100  ...   -119036.415623\n",
              "7                                0.010  ...   -119123.789921\n",
              "12                               0.100  ...   -119381.375758\n",
              "8                                0.010  ...   -119404.656366\n",
              "11                               0.100  ...   -119636.170153\n",
              "10                               0.100  ...   -119745.310236\n",
              "19                               1.000  ...   -119856.902065\n",
              "9                                0.010  ...   -119896.666355\n",
              "0                                0.001  ...   -119972.790018\n",
              "1                                0.001  ...   -120077.757760\n",
              "2                                0.001  ...   -120296.194969\n",
              "18                               1.000  ...   -120356.605501\n",
              "3                                0.001  ...   -120590.431840\n",
              "17                               1.000  ...   -120775.681590\n",
              "4                                0.001  ...   -120817.247724\n",
              "16                               1.000  ...   -121374.333354\n",
              "15                               1.000  ...   -121760.921951\n",
              "24                              10.000  ...   -123257.386236\n",
              "23                              10.000  ...   -128407.506308\n",
              "22                              10.000  ...   -136766.429438\n",
              "21                              10.000  ...   -144021.731300\n",
              "20                              10.000  ...   -147771.744726\n",
              "\n",
              "[25 rows x 3 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elastic_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"elasticnet_regression\", ElasticNet())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "elastic_param_grid = {'elasticnet_regression__alpha': [0.001,0.01,0.1,1,10],\n",
        "'elasticnet_regression__l1_ratio': [0.1,0.25,0.5,0.75,0.9]} \n",
        "\n",
        "\n",
        "gscv_elastic = GridSearchCV(elastic_pipeline, elastic_param_grid, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_elastic = gscv_elastic.fit(X, y)\n",
        "\n",
        "gscv_fitted_elastic.cv_results_['mean_test_score']\n",
        "df_elastic= pd.DataFrame(gscv_fitted_elastic.cv_results_)\n",
        "\n",
        "elastic_results = df_elastic[['param_elasticnet_regression__alpha','param_elasticnet_regression__l1_ratio', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False)\n",
        "elastic_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>select__Hits</td>\n",
              "      <td>247.556168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>select__CRuns</td>\n",
              "      <td>223.037799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>select__CRBI</td>\n",
              "      <td>121.693876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>select__CHits</td>\n",
              "      <td>120.015087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>select__Walks</td>\n",
              "      <td>110.808219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>select__PutOuts</td>\n",
              "      <td>77.918536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>dummify__Division_E</td>\n",
              "      <td>60.670585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>select__CHmRun</td>\n",
              "      <td>55.914795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>select__Assists</td>\n",
              "      <td>40.736641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>dummify__League_N</td>\n",
              "      <td>27.879970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>dummify__NewLeague_A</td>\n",
              "      <td>11.191520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>select__HmRun</td>\n",
              "      <td>4.470970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>select__RBI</td>\n",
              "      <td>2.384300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>select__Runs</td>\n",
              "      <td>-5.041710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>dummify__NewLeague_N</td>\n",
              "      <td>-11.193389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>select__Errors</td>\n",
              "      <td>-24.388977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>dummify__League_A</td>\n",
              "      <td>-27.879647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>select__Years</td>\n",
              "      <td>-49.541493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>dummify__Division_W</td>\n",
              "      <td>-60.671699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>select__CAtBat</td>\n",
              "      <td>-115.294004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>select__CWalks</td>\n",
              "      <td>-154.668795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>select__AtBat</td>\n",
              "      <td>-231.507759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Feature        Coef\n",
              "1           select__Hits  247.556168\n",
              "10         select__CRuns  223.037799\n",
              "11          select__CRBI  121.693876\n",
              "8          select__CHits  120.015087\n",
              "5          select__Walks  110.808219\n",
              "13       select__PutOuts   77.918536\n",
              "18   dummify__Division_E   60.670585\n",
              "9         select__CHmRun   55.914795\n",
              "14       select__Assists   40.736641\n",
              "17     dummify__League_N   27.879970\n",
              "20  dummify__NewLeague_A   11.191520\n",
              "2          select__HmRun    4.470970\n",
              "4            select__RBI    2.384300\n",
              "3           select__Runs   -5.041710\n",
              "21  dummify__NewLeague_N  -11.193389\n",
              "15        select__Errors  -24.388977\n",
              "16     dummify__League_A  -27.879647\n",
              "6          select__Years  -49.541493\n",
              "19   dummify__Division_W  -60.671699\n",
              "7         select__CAtBat -115.294004\n",
              "12        select__CWalks -154.668795\n",
              "0          select__AtBat -231.507759"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_elastic_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"elasticnet_regression\", ElasticNet(alpha=0.1,l1_ratio=0.9))]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "best_fitted_elastic = best_elastic_pipeline.fit(X, y)\n",
        "\n",
        "feature_names = best_fitted_elastic.named_steps['preprocessing'].get_feature_names_out()\n",
        "elastic_fitted_coefs = best_fitted_elastic.named_steps['elasticnet_regression'].coef_\n",
        "coef_df_elastic = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Coef\":elastic_fitted_coefs })\n",
        "\n",
        "coef_df_elastic.sort_values(by='Coef', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Hits is the strongest predictor in the Elastic Net model. A one-SD increase in career hits is associated with about $248k more salary. This indicates that overall hitting consistency is a major factor in determining player pay. Career Runs has the second-largest coefficient. This means players who have scored more runs over their careers tend to earn significantly higher salaries, even after controlling for other batting stats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. MSE = 118969.491456"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the results above, the most important numeric variable is CRuns, the fice most important are CRuns, Hits, CRBI, CHits, and Walks the most important categorical variable is Division E. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "ct_single_num_var = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"select\", StandardScaler(), ['CRuns']),\n",
        "    ],\n",
        "    remainder = \"drop\"\n",
        ").set_output(transform = \"pandas\")\n",
        "\n",
        "pipe_1_sing_var = Pipeline([\n",
        "    (\"prepocessing\", ct_single_num_var),\n",
        "    (\"linereg\", LinearRegression())\n",
        "])\n",
        "\n",
        "pipe_1_sing_var_fitted = pipe_1_sing_var.fit(X,y)\n",
        "\n",
        "pipe_2 = Pipeline([\n",
        "    (\"prepocessing\", ct_single_num_var),\n",
        "    (\"ridgereg\", Ridge())\n",
        "]).set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'ridgereg__alpha': [0.001,0.01,0.1,1,10]}\n",
        "\n",
        "gscv_ridge = GridSearchCV(pipe_2, alphas, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_ridge = gscv_ridge.fit(X, y)\n",
        "\n",
        "lasso_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct_single_num_var),\n",
        "  (\"lasso_regression\", Lasso())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'lasso_regression__alpha': [0.001,0.01,0.1,1,10]}\n",
        "\n",
        "\n",
        "gscv_lasso = GridSearchCV(lasso_pipeline, alphas, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_lasso = gscv_lasso.fit(X, y)\n",
        "\n",
        "elastic_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct_single_num_var),\n",
        "  (\"elasticnet_regression\", ElasticNet())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "elastic_param_grid = {'elasticnet_regression__alpha': [0.001,0.01,0.1,1,10],\n",
        "'elasticnet_regression__l1_ratio': [0.1,0.25,0.5,0.75,0.9]} \n",
        "\n",
        "\n",
        "gscv_elastic = GridSearchCV(elastic_pipeline, elastic_param_grid, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_elastic = gscv_elastic.fit(X, y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Best alpha</th>\n",
              "      <th>Best l1_ratio</th>\n",
              "      <th>CV MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OLS (single var)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>143812.935916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ridge (single var)</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>143658.517369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LASSO (single var)</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>143793.449159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Elastic Net (single var)</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>143655.076048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Model  Best alpha  Best l1_ratio         CV MSE\n",
              "0          OLS (single var)         NaN            NaN  143812.935916\n",
              "1        Ridge (single var)        10.0            NaN  143658.517369\n",
              "2        LASSO (single var)        10.0            NaN  143793.449159\n",
              "3  Elastic Net (single var)         0.1            0.5  143655.076048"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ols_cv_mse = -cross_val_score(pipe_1_sing_var, X, y, cv=5,\n",
        "                              scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "best_alpha_ridge = gscv_fitted_ridge.best_params_['ridgereg__alpha']\n",
        "ridge_cv_mse = -gscv_fitted_ridge.best_score_\n",
        "\n",
        "best_alpha_lasso = gscv_fitted_lasso.best_params_['lasso_regression__alpha']\n",
        "lasso_cv_mse = -gscv_fitted_lasso.best_score_\n",
        "\n",
        "best_alpha_en = gscv_fitted_elastic.best_params_['elasticnet_regression__alpha']\n",
        "best_l1_en = gscv_fitted_elastic.best_params_['elasticnet_regression__l1_ratio']\n",
        "en_cv_mse = -gscv_fitted_elastic.best_score_\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    'Model': ['OLS (single var)', 'Ridge (single var)', 'LASSO (single var)', 'Elastic Net (single var)'],\n",
        "    'Best alpha': [None, best_alpha_ridge, best_alpha_lasso, best_alpha_en],\n",
        "    'Best l1_ratio': [None, None, None, best_l1_en],\n",
        "    'CV MSE': [ols_cv_mse, ridge_cv_mse, lasso_cv_mse, en_cv_mse]\n",
        "})\n",
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "ct_top5_num_var = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"select\", StandardScaler(), ['CRuns', 'Hits', 'CRBI', 'CHits','Walks']),\n",
        "    ],\n",
        "    remainder = \"drop\"\n",
        ").set_output(transform = \"pandas\")\n",
        "\n",
        "pipe_1_top5_var = Pipeline([\n",
        "    (\"prepocessing\", ct_top5_num_var),\n",
        "    (\"linereg\", LinearRegression())\n",
        "])\n",
        "\n",
        "pipe_1_top5_fitted = pipe_1_top5_var.fit(X,y)\n",
        "\n",
        "pipe_2 = Pipeline([\n",
        "    (\"prepocessing\", ct_top5_num_var),\n",
        "    (\"ridgereg\", Ridge())\n",
        "]).set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'ridgereg__alpha': [0.001,0.01,0.1,1,10]}\n",
        "\n",
        "gscv_ridge = GridSearchCV(pipe_2, alphas, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_ridge = gscv_ridge.fit(X, y)\n",
        "\n",
        "lasso_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct_top5_num_var),\n",
        "  (\"lasso_regression\", Lasso())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'lasso_regression__alpha': [0.001,0.01,0.1,1,10]}\n",
        "\n",
        "\n",
        "gscv_lasso = GridSearchCV(lasso_pipeline, alphas, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_lasso = gscv_lasso.fit(X, y)\n",
        "\n",
        "elastic_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct_top5_num_var),\n",
        "  (\"elasticnet_regression\", ElasticNet())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "elastic_param_grid = {'elasticnet_regression__alpha': [0.001,0.01,0.1,1,10],\n",
        "'elasticnet_regression__l1_ratio': [0.1,0.25,0.5,0.75,0.9]} \n",
        "\n",
        "\n",
        "gscv_elastic = GridSearchCV(elastic_pipeline, elastic_param_grid, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_elastic = gscv_elastic.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Best alpha</th>\n",
              "      <th>Best l1_ratio</th>\n",
              "      <th>CV MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OLS (top 5 var)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>126047.770851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ridge (top 5 var)</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>123172.832275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LASSO (top 5 var)</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>124607.123928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Elastic Net (top 5 var)</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>122077.244186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Model  Best alpha  Best l1_ratio         CV MSE\n",
              "0          OLS (top 5 var)         NaN            NaN  126047.770851\n",
              "1        Ridge (top 5 var)        10.0            NaN  123172.832275\n",
              "2        LASSO (top 5 var)        10.0            NaN  124607.123928\n",
              "3  Elastic Net (top 5 var)         1.0           0.75  122077.244186"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ols_cv_mse = -cross_val_score(pipe_1_top5_var, X, y, cv=5,\n",
        "                              scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "best_alpha_ridge = gscv_fitted_ridge.best_params_['ridgereg__alpha']\n",
        "ridge_cv_mse = -gscv_fitted_ridge.best_score_\n",
        "\n",
        "best_alpha_lasso = gscv_fitted_lasso.best_params_['lasso_regression__alpha']\n",
        "lasso_cv_mse = -gscv_fitted_lasso.best_score_\n",
        "\n",
        "best_alpha_en = gscv_fitted_elastic.best_params_['elasticnet_regression__alpha']\n",
        "best_l1_en = gscv_fitted_elastic.best_params_['elasticnet_regression__l1_ratio']\n",
        "en_cv_mse = -gscv_fitted_elastic.best_score_\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    'Model': ['OLS (top 5 var)', 'Ridge (top 5 var)', 'LASSO (top 5 var)', 'Elastic Net (top 5 var)'],\n",
        "    'Best alpha': [None, best_alpha_ridge, best_alpha_lasso, best_alpha_en],\n",
        "    'Best l1_ratio': [None, None, None, best_l1_en],\n",
        "    'CV MSE': [ols_cv_mse, ridge_cv_mse, lasso_cv_mse, en_cv_mse]\n",
        "})\n",
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.426e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.420e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.416e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.411e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.408e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.421e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.885e+06, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.856e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.719e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.642e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.943e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.593e+04, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.442e+05, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+05, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.625e+05, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.178e+05, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+05, tolerance: 5.332e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.439e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.430e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.439e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.431e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.439e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.432e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.437e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.431e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.434e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.427e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.430e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.425e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.432e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.423e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.434e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.415e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.435e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.418e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.437e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.427e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.353e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.428e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.236e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.386e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.040e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.316e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.767e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.773e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.240e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.405e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+07, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.324e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.685e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.712e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.241e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+07, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.612e+06, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.723e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.654e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.858e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.853e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.553e+06, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.460e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.467e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.286e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.592e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.151e+06, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.508e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.141e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.795e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.579e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.479e+06, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.034e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.586e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.536e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.059e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e+06, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.068e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+06, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.803e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+06, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+06, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.269e+05, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.650e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.952e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.587e+05, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.174e+05, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.685e+05, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.049e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e+06, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+05, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.903e+05, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+05, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.639e+05, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.370e+04, tolerance: 4.708e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.905e+05, tolerance: 3.606e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+05, tolerance: 4.137e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e+06, tolerance: 4.281e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.908e+05, tolerance: 4.558e+03\n",
            "C:\\Users\\tyler\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+06, tolerance: 5.332e+03\n"
          ]
        }
      ],
      "source": [
        "X[\"Division_E\"] = (X[\"Division\"] == \"E\").astype(int)\n",
        "\n",
        "ct_top5_interact = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"select\", StandardScaler(), ['CRuns', 'Hits', 'CRBI', 'CHits','Walks']),\n",
        "        (\"dummify\", OneHotEncoder(sparse_output = False, handle_unknown=\"ignore\"), ['Division']),\n",
        "        (\"interaction1\", PolynomialFeatures(interaction_only = True), [\"CRuns\", \"Division_E\"]),\n",
        "        (\"interaction2\", PolynomialFeatures(interaction_only = True), [\"Hits\", \"Division_E\"]),\n",
        "        (\"interaction3\", PolynomialFeatures(interaction_only = True), [\"CRBI\", \"Division_E\"]),\n",
        "        (\"interaction4\", PolynomialFeatures(interaction_only = True), [\"CHits\", \"Division_E\"]),\n",
        "        (\"interaction5\", PolynomialFeatures(interaction_only = True), [\"Walks\", \"Division_E\"]),\n",
        "    ],\n",
        "    remainder = \"drop\"\n",
        ").set_output(transform = \"pandas\")\n",
        "\n",
        "pipe_1_top5_interact = Pipeline([\n",
        "    (\"prepocessing\", ct_top5_interact),\n",
        "    (\"linereg\", LinearRegression())\n",
        "])\n",
        "\n",
        "pipe_1_top5_interact_fitted = pipe_1_top5_interact.fit(X,y)\n",
        "\n",
        "pipe_2 = Pipeline([\n",
        "    (\"prepocessing\", ct_top5_interact),\n",
        "    (\"ridgereg\", Ridge())\n",
        "]).set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'ridgereg__alpha': [0.001,0.01,0.1,1,10]}\n",
        "\n",
        "gscv_ridge = GridSearchCV(pipe_2, alphas, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_ridge = gscv_ridge.fit(X, y)\n",
        "\n",
        "lasso_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct_top5_interact),\n",
        "  (\"lasso_regression\", Lasso())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'lasso_regression__alpha': [0.001,0.01,0.1,1,10]}\n",
        "\n",
        "\n",
        "gscv_lasso = GridSearchCV(lasso_pipeline, alphas, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_lasso = gscv_lasso.fit(X, y)\n",
        "\n",
        "elastic_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct_top5_interact),\n",
        "  (\"elasticnet_regression\", ElasticNet())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "elastic_param_grid = {'elasticnet_regression__alpha': [0.001,0.01,0.1,1,10],\n",
        "'elasticnet_regression__l1_ratio': [0.1,0.25,0.5,0.75,0.9]} \n",
        "\n",
        "\n",
        "gscv_elastic = GridSearchCV(elastic_pipeline, elastic_param_grid, cv = 5, scoring='neg_mean_squared_error')\n",
        "gscv_fitted_elastic = gscv_elastic.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Best alpha</th>\n",
              "      <th>Best l1_ratio</th>\n",
              "      <th>CV MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OLS (top 5 with interaction var)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>134896.044267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ridge (top 5 with interaction var)</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>134542.776381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LASSO (top 5 with interaction var)</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>132777.730262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Elastic Net (top 5 with interaction var)</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>132655.236504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Model  ...         CV MSE\n",
              "0          OLS (top 5 with interaction var)  ...  134896.044267\n",
              "1        Ridge (top 5 with interaction var)  ...  134542.776381\n",
              "2        LASSO (top 5 with interaction var)  ...  132777.730262\n",
              "3  Elastic Net (top 5 with interaction var)  ...  132655.236504\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ols_cv_mse = -cross_val_score(pipe_1_top5_interact_fitted, X, y, cv=5,\n",
        "                              scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "best_alpha_ridge = gscv_fitted_ridge.best_params_['ridgereg__alpha']\n",
        "ridge_cv_mse = -gscv_fitted_ridge.best_score_\n",
        "\n",
        "best_alpha_lasso = gscv_fitted_lasso.best_params_['lasso_regression__alpha']\n",
        "lasso_cv_mse = -gscv_fitted_lasso.best_score_\n",
        "\n",
        "best_alpha_en = gscv_fitted_elastic.best_params_['elasticnet_regression__alpha']\n",
        "best_l1_en = gscv_fitted_elastic.best_params_['elasticnet_regression__l1_ratio']\n",
        "en_cv_mse = -gscv_fitted_elastic.best_score_\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    'Model': ['OLS (top 5 with interaction var)', 'Ridge (top 5 with interaction var)', 'LASSO (top 5 with interaction var)', 'Elastic Net (top 5 with interaction var)'],\n",
        "    'Best alpha': [None, best_alpha_ridge, best_alpha_lasso, best_alpha_en],\n",
        "    'Best l1_ratio': [None, None, None, best_l1_en],\n",
        "    'CV MSE': [ols_cv_mse, ridge_cv_mse, lasso_cv_mse, en_cv_mse]\n",
        "})\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Report which combination of features and model performed best, based on the validation metric of MSE.\n",
        "\n",
        "Elastic Net with just the top 5 varibales with an alpha of 1.0 and an l1_ratio of 0.75 has the lowest MSE of all the models with 122077.244186"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part III. Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A. Ridge\n",
        "\n",
        "Ridge performed much better (best MSE around 119,144) with alpha = 1. Ridge shrinks coefficients but never forces them to zero. In my results, important variables like CRuns, Hits, CRBI, Walks, PutOuts still had relatively large coefficients, but noticeably smaller than in linear regression. This means Ridge reduced overfitting by damping noisy variables without removing them entirely.\n",
        "\n",
        "B. LASSO\n",
        "\n",
        "When I compared the LASSO model from Part I to the three LASSO models in Part II, the lambda values were not the same, and the MSE values were also different. This outcome is fully expected because the models are not using the same predictors and LASSOs optimal lambda depends on the feature set being used. LASSOs performance depends directly on the available predictors, so each models CV MSE reflects how much information those predictors carry. More informative features leads to  better MSE. Simplified subsets leads to worse MSE\n",
        "\n",
        "C. Elastic Net\n",
        "\n",
        "Ridge cannot zero out coefficients. LASSO can zero out too many coefficients when predictors are correlated. Elastic Net balances both penalties and avoids the weaknesses of each individual method. Elastic Net has two tuning parameters instead of one, so it has more flexibility to adapt to the structure of the data. The extra flexibility allows it to keep important variables (like Ridge), remove unneeded ones (like LASSO), and shrink correlated groups of predictors together. All of this leads to consistently lower cross-validated MSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part IV: Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>select__Hits</td>\n",
              "      <td>88.560103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>select__CRBI</td>\n",
              "      <td>83.958757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>select__Walks</td>\n",
              "      <td>68.781442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>select__CRuns</td>\n",
              "      <td>60.653269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>select__CHits</td>\n",
              "      <td>54.162506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Feature       Coef\n",
              "1   select__Hits  88.560103\n",
              "2   select__CRBI  83.958757\n",
              "4  select__Walks  68.781442\n",
              "0  select__CRuns  60.653269\n",
              "3  select__CHits  54.162506"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elastic_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct_top5_num_var),\n",
        "  (\"elasticnet_regression\", ElasticNet(alpha=1,l1_ratio=0.75))]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "gscv_fitted_elastic = elastic_pipeline.fit(X, y)\n",
        "\n",
        "feature_names = elastic_pipeline.named_steps[\"preprocessing\"].get_feature_names_out()\n",
        "coefs = elastic_pipeline.named_steps[\"elasticnet_regression\"].coef_\n",
        "\n",
        "coef_df_elasic = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Coef\": coefs })\n",
        "\n",
        "coef_df_elasic.sort_values(by='Coef', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "122077.24418555049\n"
          ]
        }
      ],
      "source": [
        "cv_mse = -cross_val_score(elastic_pipeline, X, y, cv=5,\n",
        "                          scoring='neg_mean_squared_error').mean()\n",
        "print(cv_mse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The best-performing model was the Elastic Net model using only the Top 5 numeric predictors, with a cross-validated MSE of 122,077.24. This model outperformed both Ridge and LASSO because the Elastic Net penalty balances the benefits of both methods: Ridges stability with correlated predictors and LASSOs ability to shrink weaker variables.\n",
        "\n",
        "I refit this final Elastic Net pipeline on the full Hitters dataset using the optimal hyperparameters from the grid search. The fitted model shows that the five key career totals, CRuns, Hits, CRBI, CHits, and Walks, remain the strongest predictors of player salary. The models predictions track the observed salaries closely, indicating good overall fit without excessive overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from plotnine import *\n",
        "\n",
        "best_model = gscv_fitted_elastic\n",
        "y_hat = best_model.predict(X)\n",
        "\n",
        "df_plot = pd.DataFrame({\n",
        "    \"Actual\": y,\n",
        "    \"Predicted\": y_hat\n",
        "})\n",
        "\n",
        "# plotnine plot\n",
        "(\n",
        "    ggplot(df_plot, aes(x='Actual', y='Predicted')) +\n",
        "    geom_point(alpha=0.6) +\n",
        "    geom_abline(intercept=0, slope=1, color='red') +\n",
        "    labs(title=\"Predicted vs Actual Salary\",\n",
        "         x=\"Actual Salary\",\n",
        "         y=\"Predicted Salary\") +\n",
        "    theme_bw()\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
